{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Pattern Recognition - Machine Learning** | Assignment 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pzWFLo8HInnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) **Operations with Vectors and Matrices**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hKzW8Erhgxop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i) Creating matrices of integers for processing."
      ],
      "metadata": {
        "id": "ttDTiRWPhXtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# We define the low and upper bounds of the integer values in the matrices, without affecting the general idea.\n",
        "# Seed: last 4 digits of the student ID: 0021->21\n",
        "np.random.seed(21)\n",
        "\n",
        "# Creating a 3x4 matrix of integers\n",
        "X = np.random.randint(low=-500, high=500, size=(3, 4))\n",
        "print(\"Matrix X (3x4):\\n\")\n",
        "print(X)\n",
        "\n",
        "# Creating a 4x3 matrix of integers\n",
        "Y = np.random.randint(low=-500, high=500, size=(4, 3))\n",
        "print(\"----------------------------------------------------\")\n",
        "print(\"Matrix Y (4x3):\\n\")\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "plS5o-1dhtkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii) Creating vectors of integers for processing"
      ],
      "metadata": {
        "id": "xJSCbMLojl46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the low and upper bounds of the integer values in the vectors, without affecting the general idea\n",
        "\n",
        "# Seed: last 4 digits of the student ID: 0021->21\n",
        "np.random.seed(21)\n",
        "\n",
        "# Creating a 4-dimensional vector of integers, a\n",
        "a = np.random.randint(low=-500, high=500, size=(4,))\n",
        "print(\"Vector a:\\n\")\n",
        "print(a)\n",
        "\n",
        "# Creating a 4-dimensional vector of integers, b\n",
        "b = np.random.randint(low=-500, high=500, size=(4,))\n",
        "print(\"----------------------------------------------------\")\n",
        "print(\"Vector b:\\n\")\n",
        "print(b)\n"
      ],
      "metadata": {
        "id": "lKfkkQtlj1Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.1) Inner product of vectors a and b ($a^T b$)"
      ],
      "metadata": {
        "id": "wsKKpNxDlfVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use of np.inner\n",
        "c = np.inner(a, b)\n",
        "print(\"c = \\n\")\n",
        "print(c)\n",
        "\n"
      ],
      "metadata": {
        "id": "bs7CVqrhoHpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2) Product of matrix X and vector a ($Xa$)"
      ],
      "metadata": {
        "id": "BJLVUGe1uW5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can omit the transpose '.T' operation when multiplying matrix X with vector a, without affecting the result.\n",
        "res = X*a.T\n",
        "print(\"res = \\n\")\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "Y0W3JCm2wE9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3) Product of two matrices X and Y ($XY$)"
      ],
      "metadata": {
        "id": "zKKDZgBf5FaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplication of X, Y matrices\n",
        "mult_res = np.dot(X, Y)\n",
        "\n",
        "print(\"mult_res = XY = \\n\")\n",
        "print(mult_res)"
      ],
      "metadata": {
        "id": "aCAhBTDL5RrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.4) Euclidean norm of vector a"
      ],
      "metadata": {
        "id": "ZgK7jALZ7GqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm=np.linalg.norm(a)\n",
        "print(\"norm of a = \\n\")\n",
        "print(norm)"
      ],
      "metadata": {
        "id": "MrGZupPb7G9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) **Calculation of Derivatives**"
      ],
      "metadata": {
        "id": "1Ob0j-v5CLyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1) Derivative of $f(x)$\n",
        "We use rules 89 and 61 (pages 10-11) from the Matrix Cookbook."
      ],
      "metadata": {
        "id": "H55oA7u5Cob8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2) Global minimum problem"
      ],
      "metadata": {
        "id": "4hAZ_EcpQd5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use rules 4, 5, 15, 101, and 116 from Matrix Cookbook."
      ],
      "metadata": {
        "id": "qLSjigLQVoLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) **Gradient Descent Algorithm**"
      ],
      "metadata": {
        "id": "zhFedo5yiWrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first part of the code implements the Gradient Descent algorithm with a learning rate of 0.5 and 10 iterations. It also defines a precision of 0.0001. This first part of the code represents the initial simple approach without any changes to the learning rate or the iterations of the algorithm."
      ],
      "metadata": {
        "id": "yaJYVKi9idCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from decimal import *\n",
        "\n",
        "# definitions of the functions and their partial derivatives\n",
        "def f1_x1_x2(x1, x2):\n",
        "    return (x1-2) ** 2 + (x2-3) ** 2\n",
        "\n",
        "def f2_x1_x2(x1, x2):\n",
        "    return (1 - (x2-3)) ** 2 + 20 * ((x1+3) - (x2-3) ** 2) ** 2\n",
        "\n",
        "def df1_x1(x1, x2):\n",
        "    return (2 * (x1-2))\n",
        "\n",
        "def df1_x2(x1, x2):\n",
        "    return (2 * (x1-3))\n",
        "\n",
        "def df2_x1(x1, x2):\n",
        "    return (40 * (x1-3) - 40 * (x2-3) ** 2)\n",
        "\n",
        "def df2_x2(x1, x2):\n",
        "    return (2 * (x2-4) - 80 * (x1+3) * (x2-3) + 80 * (x2-3) ** 3)\n",
        "\n",
        "# initializing variables\n",
        "\n",
        "rate = 0.5                      # Learning rate\n",
        "precision = 0.0001\n",
        "curX1 = 0\n",
        "curX2 = 0\n",
        "maxIters = 10                   # maximum number of iterations (modifiable)\n",
        "iters = 0                       # iteration counter\n",
        "iter_list1 = []                 # list stores the iteration number, to use later in the plot\n",
        "iter_list2 = []                 # list stores the iteration number, to use later in the plot\n",
        "f1_values_list = []\n",
        "f2_values_list = []\n",
        "\n",
        "print(\"\\n-------------------------------------f1(x)-----------------------------------------------\\n\")\n",
        "\n",
        "# Iterations for f1(x)\n",
        "for aIter in range(maxIters):\n",
        "\n",
        "      prevX1 = curX1\n",
        "      curX1 = curX1 - rate * df1_x1(curX1, curX2)\n",
        "      diff1 = abs(curX1-prevX1)\n",
        "      prevX2 = curX2\n",
        "      curX2 = curX2 - rate * df1_x2(curX1, curX2)\n",
        "      diff2 = abs(curX2 - prevX2)\n",
        "      print(\"Iteration \", aIter + 1, \"\\n(x1,x2)=(\",curX1, \",\", curX2, \") => f1(\", curX1, \",\", curX2, \")=\", f1_x1_x2(curX1, curX2))  # Print iterations\n",
        "\n",
        "      f1_values_list.append(float(f1_x1_x2(curX1, curX2)))  # contains values of function f1 at each (x1,x2) point\n",
        "      iter_list1.append(int(aIter+1))                       # contains iterations number for printing later\n",
        "\n",
        "      if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "          # if one/both of the 2 variables x1 or x2 (prevX and curX) are too close to each other (less than the precision) then terminate the algorithm\n",
        "          print(\"The local minimum for f1(x) = (x1-1)^2+(x2-3)^2 occurs at (x1,x2)=(\", curX1, \",\", curX2, \") after underflowing\"\n",
        "            \" precision threshold and is\", f1_x1_x2(curX1, curX2))\n",
        "          break\n",
        "\n",
        "\n",
        "# initializing variables\n",
        "cur_X1 = 0\n",
        "cur_X2 = 0\n",
        "\n",
        "print(\"\\n-------------------------------------f2(x)-----------------------------------------------\\n\")\n",
        "\n",
        "# Iterations for f2(x)\n",
        "for aIter in range(maxIters):\n",
        "\n",
        "      prev_X1 = cur_X1\n",
        "      cur_X1 = cur_X1 - rate * df2_x1(cur_X1, cur_X2)\n",
        "      diff1 = abs(cur_X1-prev_X1)\n",
        "      prev_X2 = cur_X2\n",
        "      cur_X2 = cur_X2 - rate * df2_x2(cur_X1, cur_X2)\n",
        "      diff2 = abs(cur_X2 - prev_X2)\n",
        "      print(\"Iteration \", aIter+1, \"\\n(x1,x2)=(\", cur_X1, \",\", cur_X2, \") => f2(\", cur_X1, \",\", cur_X2, \")=\", f2_x1_x2(cur_X1, cur_X2))  # Print iterations\n",
        "\n",
        "      f2_values_list.append(float(f2_x1_x2(cur_X1, cur_X2)))        # contains values of function f1 at each (x1,x2) point\n",
        "      iter_list2.append(int(aIter + 1))                             # contains iterations number for printing later\n",
        "\n",
        "      if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "        # if prevX and curX are too close to each other (less than the precision) then terminate the algorithm\n",
        "        print(\"The local minimum for f2(x) = (1-(x2-3))^2+20*((x1+3)-(x2-3)^2)^2 occurs at (x1,x2)=(\", cur_X1, \",\", cur_X2, \") after underflowing\"\n",
        "            \" precision threshold and is\", f2_x1_x2(cur_X1, cur_X2))\n",
        "        break\n",
        "\n",
        "# Plotting for f1\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "plt.scatter(iter_list1, f1_values_list, marker='.', color='red', s=60)\n",
        "plt.plot([min(iter_list1), max(iter_list1)], [min(f1_values_list), max(f1_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"f1(x1,x2)\")\n",
        "plt.show()\n",
        "\n",
        "# Plotting for f2\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "plt.scatter(iter_list2, f2_values_list, marker='.', color='red', s=60)\n",
        "plt.plot([min(iter_list2), max(iter_list2)], [min(f2_values_list), max(f2_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"f2(x1,x2)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8hJMADw_vKd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that there is an overflow in the float representation during the 4th iteration of the algorithm for f2. This is expected because the learning rate is quite large, resulting in the curX (new x) values increasing rapidly and consequently causing a significant increase in the values of the derivatives df2_x1 and df2_x2 with respect to x1 and x2. Therefore, a lower learning rate should be set to ensure that the transitions between x values are much smaller, leading to a slower convergence rate in each iteration (with a smaller \"step\"). This code segment, although designed to include plotting, cannot proceed due to the overflow error."
      ],
      "metadata": {
        "id": "CzBpMc2qwRY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second part of the question (3) asks for the variation of the learning rate and the number of iterations performed by the algorithm. The following code segment implements the algorithm starting with a learning rate of 0.5 and a precision of 0.0001. The algorithm is implemented with a while loop to present the results for all possible combinations of learning rate and precision. After completing the algorithm, we divide the initial parameters by 10. The while loop structure allows for setting a learning rate and testing a range of precisions from 0.0001 to 0.00000001 with a division by 10 each time. Once this loop finishes, the learning rate and precision are divided by 10 again, and the previous set of values is repeated. The learning rate starts from 0.0001 (to avoid memory overflows) and goes down to 0.00000001. Additionally, each resulting plot includes the learning rate and precision being used, while the remaining results and intermediate stages of the algorithm are displayed in the terminal. In total, there are 25 combinations of rate and precision for 2 functions (a total of 50 plots), while the number of iterations remains constant at 200 (which can be manually changed)."
      ],
      "metadata": {
        "id": "8gncVSZ6nCsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# definitions of the functions and their partial derivatives\n",
        "def f1_x1_x2(x1, x2):\n",
        "    return (x1-2) ** 2 + (x2-3) ** 2\n",
        "\n",
        "def f2_x1_x2(x1, x2):\n",
        "    return (1 - (x2-3)) ** 2 + 20 * ((x1+3) - (x2-3) ** 2) ** 2\n",
        "\n",
        "def df1_x1(x1, x2):\n",
        "    return (2 * (x1-2))\n",
        "\n",
        "def df1_x2(x1, x2):\n",
        "    return (2 * (x1-3))\n",
        "\n",
        "def df2_x1(x1, x2):\n",
        "    return (40 * (x1-3) - 40 * (x2-3) ** 2)\n",
        "\n",
        "def df2_x2(x1, x2):\n",
        "    return (2 * (x2-4) - 80 * (x1+3) * (x2-3) + 80 * (x2-3) ** 3)\n",
        "\n",
        "# initializing variables\n",
        "\n",
        "rate = 0.0001                          # Learning rate\n",
        "\n",
        "while (rate >= 0.00000001):\n",
        "\n",
        "    precision = 0.0001\n",
        "    while (precision >= 0.00000001):\n",
        "\n",
        "        curX1 = 0\n",
        "        curX2 = 0\n",
        "        maxIters = 200                  # maximum number of iterations (modifiable)\n",
        "        iters = 0                       # iteration counter\n",
        "        iter_list1 = []                 # list stores the iteration number, to use later in the plot\n",
        "        iter_list2 = []                 # list stores the iteration number, to use later in the plot\n",
        "        f1_values_list = []             # list stores the iteration number, to use later in the plot\n",
        "        f2_values_list = []             # list stores the iteration number, to use later in the plot\n",
        "\n",
        "        print(\"\\n------------------------f1(x)-------rate =\", rate,\", precision =\", precision,\"----------------------------------------\\n\")\n",
        "\n",
        "        # Iterations for f1(x)\n",
        "        for aIter in range(maxIters):\n",
        "\n",
        "              prevX1 = curX1\n",
        "              curX1 = curX1 - rate * df1_x1(curX1, curX2)\n",
        "              diff1 = abs(curX1-prevX1)\n",
        "              prevX2 = curX2\n",
        "              curX2 = curX2 - rate * df1_x2(curX1, curX2)\n",
        "              diff2 = abs(curX2 - prevX2)\n",
        "              print(\"Iteration \", aIter + 1, \"\\n(x1,x2)=(\",curX1, \",\", curX2, \") => f1(\", curX1, \",\", curX2, \")=\", f1_x1_x2(curX1, curX2))  # Print iterations\n",
        "\n",
        "              f1_values_list.append(float(f1_x1_x2(curX1, curX2)))  # contains values of function f1 at each (x1,x2) point\n",
        "              iter_list1.append(int(aIter+1))                       # contains iterations number for printing later\n",
        "\n",
        "              if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "                    # if one/both of the 2 variables x1 or x2 (prevX and curX) are too close to each other (less than the precision) then terminate the algorithm\n",
        "                    print(\"The local minimum for f1(x) = (x1-1)^2+(x2-3)^2 occurs at (x1,x2)=(\", curX1, \",\", curX2, \") after underflowing\"\n",
        "                          \" precision threshold and is\", f1_x1_x2(curX1, curX2))\n",
        "                    break\n",
        "\n",
        "\n",
        "        # initializing variables\n",
        "\n",
        "        cur_X1 = 0\n",
        "        cur_X2 = 0\n",
        "\n",
        "        print(\"\\n------------------------f2(x)-------rate =\", rate,\", precision =\", precision,\"----------------------------------------\\n\")\n",
        "\n",
        "        # Iterations for f2(x)\n",
        "        for aIter in range(maxIters):\n",
        "\n",
        "              prev_X1 = cur_X1\n",
        "              cur_X1 = cur_X1 - rate * df2_x1(cur_X1, cur_X2)\n",
        "              diff1 = abs(cur_X1-prev_X1)\n",
        "              prev_X2 = cur_X2\n",
        "              cur_X2 = cur_X2 - rate * df2_x2(cur_X1, cur_X2)\n",
        "              diff2 = abs(cur_X2 - prev_X2)\n",
        "              print(\"Iteration \", aIter+1, \"\\n(x1,x2)=(\", cur_X1, \",\", cur_X2, \") => f2(\", cur_X1, \",\", cur_X2, \")=\", f2_x1_x2(cur_X1, cur_X2))  # Print iterations\n",
        "\n",
        "              f2_values_list.append(float(f2_x1_x2(cur_X1, cur_X2)))        # contains values of function f1 at each (x1,x2) point\n",
        "              iter_list2.append(int(aIter + 1))                             # contains iterations number for printing later\n",
        "\n",
        "              if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "                    # if one/both of the 2 variables x1 or x2 (prevX and curX) are too close to each other (less than the precision) then terminate the algorithm\n",
        "                    print(\"The local minimum for f2(x) = (1-(x2-3))^2+20*((x1+3)-(x2-3)^2)^2 occurs at (x1,x2)=(\", cur_X1, \",\", cur_X2, \") after underflowing\"\n",
        "                        \" precision threshold and is\", f2_x1_x2(cur_X1, cur_X2))\n",
        "                    break\n",
        "\n",
        "        # Plotting for f1\n",
        "\n",
        "        plt.figure(figsize = (8,6))\n",
        "        plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "        plt.scatter(iter_list1, f1_values_list, marker='.', color='red', s=0.6)\n",
        "        plt.plot([min(iter_list1), max(iter_list1)], [min(f1_values_list), max(f1_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"f1(x1,x2)\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plotting for f2\n",
        "\n",
        "        plt.figure(figsize = (8,6))\n",
        "        plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "        plt.scatter(iter_list2, f2_values_list, marker='.', color='red', s=0.6)\n",
        "        plt.plot([min(iter_list2), max(iter_list2)], [min(f2_values_list), max(f2_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"f2(x1,x2)\")\n",
        "        plt.show()\n",
        "        precision = precision / 10      # preparing for next combination of learning rate and precision\n",
        "    rate = rate / 10"
      ],
      "metadata": {
        "id": "_k7d8QSm4avh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next code segment, the 25 combinations of learning rate and precision are repeated, but each combination is applied with a different number of iterations (starting from T=50 and increasing by 100). With each change in the learning rate, T is also modified accordingly. This allows for a better comparison between the previous plots and the new ones."
      ],
      "metadata": {
        "id": "NDk2onZKnFZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# definitions of the functions and their partial derivatives\n",
        "def f1_x1_x2(x1, x2):\n",
        "    return (x1-2) ** 2 + (x2-3) ** 2\n",
        "\n",
        "def f2_x1_x2(x1, x2):\n",
        "    return (1 - (x2-3)) ** 2 + 20 * ((x1+3) - (x2-3) ** 2) ** 2\n",
        "\n",
        "def df1_x1(x1, x2):\n",
        "    return (2 * (x1-2))\n",
        "\n",
        "def df1_x2(x1, x2):\n",
        "    return (2 * (x1-3))\n",
        "\n",
        "def df2_x1(x1, x2):\n",
        "    return (40 * (x1-3) - 40 * (x2-3) ** 2)\n",
        "\n",
        "def df2_x2(x1, x2):\n",
        "    return (2 * (x2-4) - 80 * (x1+3) * (x2-3) + 80 * (x2-3) ** 3)\n",
        "\n",
        "# initializing variables\n",
        "\n",
        "rate = 0.0001                          # Learning rate\n",
        "maxIters = 50                         # maximum number of iterations (will change in the loop)\n",
        "\n",
        "while (rate >= 0.00000001):\n",
        "\n",
        "    precision = 0.0001\n",
        "    while (precision >= 0.00000001):\n",
        "\n",
        "        curX1 = 0\n",
        "        curX2 = 0\n",
        "        iters = 0                       # iteration counter\n",
        "        iter_list1 = []                 # list stores the iteration number, to use later in the plot\n",
        "        iter_list2 = []                 # list stores the iteration number, to use later in the plot\n",
        "        f1_values_list = []             # list stores the iteration number, to use later in the plot\n",
        "        f2_values_list = []             # list stores the iteration number, to use later in the plot\n",
        "\n",
        "        print(\"\\n------------------------f1(x)-------rate =\", rate,\", precision =\", precision,\"----------------------------------------\\n\")\n",
        "\n",
        "        # Iterations for f1(x)\n",
        "        for aIter in range(maxIters):\n",
        "\n",
        "              prevX1 = curX1\n",
        "              curX1 = curX1 - rate * df1_x1(curX1, curX2)\n",
        "              diff1 = abs(curX1-prevX1)\n",
        "              prevX2 = curX2\n",
        "              curX2 = curX2 - rate * df1_x2(curX1, curX2)\n",
        "              diff2 = abs(curX2 - prevX2)\n",
        "              print(\"Iteration \", aIter + 1, \"\\n(x1,x2)=(\",curX1, \",\", curX2, \") => f1(\", curX1, \",\", curX2, \")=\", f1_x1_x2(curX1, curX2))  # Print iterations\n",
        "\n",
        "              f1_values_list.append(float(f1_x1_x2(curX1, curX2)))  # contains values of function f1 at each (x1,x2) point\n",
        "              iter_list1.append(int(aIter+1))                       # contains iterations number for printing later\n",
        "\n",
        "              if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "                    # if one/both of the 2 variables x1 or x2 (prevX and curX) are too close to each other (less than the precision) then terminate the algorithm\n",
        "                    print(\"The local minimum for f1(x) = (x1-1)^2+(x2-3)^2 occurs at (x1,x2)=(\", curX1, \",\", curX2, \") after underflowing\"\n",
        "                          \" precision threshold and is\", f1_x1_x2(curX1, curX2))\n",
        "                    break\n",
        "\n",
        "\n",
        "        # initializing variables\n",
        "\n",
        "        cur_X1 = 0\n",
        "        cur_X2 = 0\n",
        "\n",
        "        print(\"\\n------------------------f2(x)-------rate =\", rate,\", precision =\", precision,\"----------------------------------------\\n\")\n",
        "\n",
        "        # Iterations for f2(x)\n",
        "        for aIter in range(maxIters):\n",
        "\n",
        "              prev_X1 = cur_X1\n",
        "              cur_X1 = cur_X1 - rate * df2_x1(cur_X1, cur_X2)\n",
        "              diff1 = abs(cur_X1-prev_X1)\n",
        "              prev_X2 = cur_X2\n",
        "              cur_X2 = cur_X2 - rate * df2_x2(cur_X1, cur_X2)\n",
        "              diff2 = abs(cur_X2 - prev_X2)\n",
        "              print(\"Iteration \", aIter+1, \"\\n(x1,x2)=(\", cur_X1, \",\", cur_X2, \") => f2(\", cur_X1, \",\", cur_X2, \")=\", f2_x1_x2(cur_X1, cur_X2))  # Print iterations\n",
        "\n",
        "              f2_values_list.append(float(f2_x1_x2(cur_X1, cur_X2)))        # contains values of function f1 at each (x1,x2) point\n",
        "              iter_list2.append(int(aIter + 1))                             # contains iterations number for printing later\n",
        "\n",
        "              if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "                    # if one/both of the 2 variables x1 or x2 (prevX and curX) are too close to each other (less than the precision) then terminate the algorithm\n",
        "                    print(\"The local minimum for f2(x) = (1-(x2-3))^2+20*((x1+3)-(x2-3)^2)^2 occurs at (x1,x2)=(\", cur_X1, \",\", cur_X2, \") after underflowing\"\n",
        "                        \" precision threshold and is\", f2_x1_x2(cur_X1, cur_X2))\n",
        "                    break\n",
        "\n",
        "        # Plotting for f1\n",
        "\n",
        "        plt.figure(figsize = (8,6))\n",
        "        plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "        plt.scatter(iter_list1, f1_values_list, marker='.', color='red', s=0.6)\n",
        "        plt.plot([min(iter_list1), max(iter_list1)], [min(f1_values_list), max(f1_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"f1(x1,x2)\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plotting for f2\n",
        "\n",
        "        plt.figure(figsize = (8,6))\n",
        "        plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "        plt.scatter(iter_list2, f2_values_list, marker='.', color='red', s=0.6)\n",
        "        plt.plot([min(iter_list2), max(iter_list2)], [min(f2_values_list), max(f2_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"f2(x1,x2)\")\n",
        "        plt.show()\n",
        "        precision = precision / 10      # preparing for next combination of learning rate and precision\n",
        "    rate = rate / 10\n",
        "    maxIters = maxIters + 100"
      ],
      "metadata": {
        "id": "oa5vhU0B9JPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The question accepts a qualitative rather than a quantitative answer: in general, each problem is distinct with its own parameters and constraints. Therefore, it is important to properly combine the learning rate, precision, and iterations.\n",
        "\n",
        "1. Generally, when we have a small learning rate, meaning small \"steps\" towards the optimal point, we need many iterations for the algorithm to converge to it, especially if the initial values are far from the optimal point.\n",
        "\n",
        "2. On the other hand, if the learning rate is large and the initial values are far from the optimal point, fewer iterations of the algorithm will be required.\n",
        "\n",
        "3. However, if the learning rate is large and the initial values are close to the optimal point, the algorithm may either diverge from the optimal point or get trapped around it without ever approaching it satisfactorily.\n",
        "\n",
        "* For large values of the learning rate, the algorithm traverses the different X values with large \"steps.\" This can cause it to overshoot the optimal point (minimum in this case) and continue beyond it, resulting in unstable results and unpredictability.\n",
        "* Conversely, if the learning rate is very small, the algorithm moves through the different X values with small \"steps\" and takes a long time to approach the optimal point. This implies an increased computational and time complexity in solving the problem.\n",
        "* If we start to modify the initial values of the variables for the algorithm's initialization, we will observe that if these values are very far from the optimal point, the algorithm will converge very slowly to it or may not converge satisfactorily unless there are enough iterations. On the other hand, if the initial values of the variables for the initialization of the algorithm are close to the optimal point, the algorithm may converge very quickly to it.\n",
        "\n",
        "In the following code segments, we observe what happens when we only modify the number of iterations for the two functions while keeping the other parameters constant.\n"
      ],
      "metadata": {
        "id": "Wz-kd1fVnFhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**400 iterations**"
      ],
      "metadata": {
        "id": "TqRRPITqE9At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from decimal import *\n",
        "\n",
        "# definitions of the functions and their partial derivatives\n",
        "def f1_x1_x2(x1, x2):\n",
        "    return (x1-2) ** 2 + (x2-3) ** 2\n",
        "\n",
        "def f2_x1_x2(x1, x2):\n",
        "    return (1 - (x2-3)) ** 2 + 20 * ((x1+3) - (x2-3) ** 2) ** 2\n",
        "\n",
        "def df1_x1(x1, x2):\n",
        "    return (2 * (x1-2))\n",
        "\n",
        "def df1_x2(x1, x2):\n",
        "    return (2 * (x1-3))\n",
        "\n",
        "def df2_x1(x1, x2):\n",
        "    return (40 * (x1-3) - 40 * (x2-3) ** 2)\n",
        "\n",
        "def df2_x2(x1, x2):\n",
        "    return (2 * (x2-4) - 80 * (x1+3) * (x2-3) + 80 * (x2-3) ** 3)\n",
        "\n",
        "# initializing variables\n",
        "\n",
        "rate = 0.0005                      # Learning rate\n",
        "precision = 0.000001\n",
        "curX1 = 0\n",
        "curX2 = 0\n",
        "maxIters = 400                   # maximum number of iterations (modifiable)\n",
        "iters = 0                       # iteration counter\n",
        "iter_list1 = []                 # list stores the iteration number, to use later in the plot\n",
        "iter_list2 = []                 # list stores the iteration number, to use later in the plot\n",
        "f1_values_list = []\n",
        "f2_values_list = []\n",
        "\n",
        "print(\"\\n-------------------------------------f1(x)-----------------------------------------------\\n\")\n",
        "\n",
        "# Iterations for f1(x)\n",
        "for aIter in range(maxIters):\n",
        "\n",
        "      prevX1 = curX1\n",
        "      curX1 = curX1 - rate * df1_x1(curX1, curX2)\n",
        "      diff1 = abs(curX1-prevX1)\n",
        "      prevX2 = curX2\n",
        "      curX2 = curX2 - rate * df1_x2(curX1, curX2)\n",
        "      diff2 = abs(curX2 - prevX2)\n",
        "      print(\"Iteration \", aIter + 1, \"\\n(x1,x2)=(\",curX1, \",\", curX2, \") => f1(\", curX1, \",\", curX2, \")=\", f1_x1_x2(curX1, curX2))  # Print iterations\n",
        "\n",
        "      f1_values_list.append(float(f1_x1_x2(curX1, curX2)))  # contains values of function f1 at each (x1,x2) point\n",
        "      iter_list1.append(int(aIter+1))                       # contains iterations number for printing later\n",
        "\n",
        "      if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "          # if one/both of the 2 variables x1 or x2 (prevX and curX) are too close to each other (less than the precision) then terminate the algorithm\n",
        "          print(\"The local minimum for f1(x) = (x1-1)^2+(x2-3)^2 occurs at (x1,x2)=(\", curX1, \",\", curX2, \") after underflowing\"\n",
        "            \" precision threshold and is\", f1_x1_x2(curX1, curX2))\n",
        "          break\n",
        "\n",
        "\n",
        "# initializing variables\n",
        "cur_X1 = 0\n",
        "cur_X2 = 0\n",
        "\n",
        "print(\"\\n-------------------------------------f2(x)-----------------------------------------------\\n\")\n",
        "\n",
        "# Iterations for f2(x)\n",
        "for aIter in range(maxIters):\n",
        "\n",
        "      prev_X1 = cur_X1\n",
        "      cur_X1 = cur_X1 - rate * df2_x1(cur_X1, cur_X2)\n",
        "      diff1 = abs(cur_X1-prev_X1)\n",
        "      prev_X2 = cur_X2\n",
        "      cur_X2 = cur_X2 - rate * df2_x2(cur_X1, cur_X2)\n",
        "      diff2 = abs(cur_X2 - prev_X2)\n",
        "      print(\"Iteration \", aIter+1, \"\\n(x1,x2)=(\", cur_X1, \",\", cur_X2, \") => f2(\", cur_X1, \",\", cur_X2, \")=\", f2_x1_x2(cur_X1, cur_X2))  # Print iterations\n",
        "\n",
        "      f2_values_list.append(float(f2_x1_x2(cur_X1, cur_X2)))        # contains values of function f1 at each (x1,x2) point\n",
        "      iter_list2.append(int(aIter + 1))                             # contains iterations number for printing later\n",
        "\n",
        "      if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "        # if prevX and curX are too close to each other (less than the precision) then terminate the algorithm\n",
        "        print(\"The local minimum for f2(x) = (1-(x2-3))^2+20*((x1+3)-(x2-3)^2)^2 occurs at (x1,x2)=(\", cur_X1, \",\", cur_X2, \") after underflowing\"\n",
        "            \" precision threshold and is\", f2_x1_x2(cur_X1, cur_X2))\n",
        "        break\n",
        "\n",
        "# Plotting for f1\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "plt.scatter(iter_list1, f1_values_list, marker='.', color='red', s=0.5)\n",
        "plt.plot([min(iter_list1), max(iter_list1)], [min(f1_values_list), max(f1_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"f1(x1,x2)\")\n",
        "plt.show()\n",
        "\n",
        "# Plotting for f2\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "plt.scatter(iter_list2, f2_values_list, marker='.', color='red', s=0.5)\n",
        "plt.plot([min(iter_list2), max(iter_list2)], [min(f2_values_list), max(f2_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"f2(x1,x2)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8aGxzg3nE59l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**200 iterations**"
      ],
      "metadata": {
        "id": "v9qEvrICFDMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from decimal import *\n",
        "\n",
        "# definitions of the functions and their partial derivatives\n",
        "def f1_x1_x2(x1, x2):\n",
        "    return (x1-2) ** 2 + (x2-3) ** 2\n",
        "\n",
        "def f2_x1_x2(x1, x2):\n",
        "    return (1 - (x2-3)) ** 2 + 20 * ((x1+3) - (x2-3) ** 2) ** 2\n",
        "\n",
        "def df1_x1(x1, x2):\n",
        "    return (2 * (x1-2))\n",
        "\n",
        "def df1_x2(x1, x2):\n",
        "    return (2 * (x1-3))\n",
        "\n",
        "def df2_x1(x1, x2):\n",
        "    return (40 * (x1-3) - 40 * (x2-3) ** 2)\n",
        "\n",
        "def df2_x2(x1, x2):\n",
        "    return (2 * (x2-4) - 80 * (x1+3) * (x2-3) + 80 * (x2-3) ** 3)\n",
        "\n",
        "# initializing variables\n",
        "\n",
        "rate = 0.0005                      # Learning rate\n",
        "precision = 0.000001\n",
        "curX1 = 0\n",
        "curX2 = 0\n",
        "maxIters = 200                   # maximum number of iterations (modifiable)\n",
        "iters = 0                       # iteration counter\n",
        "iter_list1 = []                 # list stores the iteration number, to use later in the plot\n",
        "iter_list2 = []                 # list stores the iteration number, to use later in the plot\n",
        "f1_values_list = []\n",
        "f2_values_list = []\n",
        "\n",
        "print(\"\\n-------------------------------------f1(x)-----------------------------------------------\\n\")\n",
        "\n",
        "# Iterations for f1(x)\n",
        "for aIter in range(maxIters):\n",
        "\n",
        "      prevX1 = curX1\n",
        "      curX1 = curX1 - rate * df1_x1(curX1, curX2)\n",
        "      diff1 = abs(curX1-prevX1)\n",
        "      prevX2 = curX2\n",
        "      curX2 = curX2 - rate * df1_x2(curX1, curX2)\n",
        "      diff2 = abs(curX2 - prevX2)\n",
        "      print(\"Iteration \", aIter + 1, \"\\n(x1,x2)=(\",curX1, \",\", curX2, \") => f1(\", curX1, \",\", curX2, \")=\", f1_x1_x2(curX1, curX2))  # Print iterations\n",
        "\n",
        "      f1_values_list.append(float(f1_x1_x2(curX1, curX2)))  # contains values of function f1 at each (x1,x2) point\n",
        "      iter_list1.append(int(aIter+1))                       # contains iterations number for printing later\n",
        "\n",
        "      if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "          # if one/both of the 2 variables x1 or x2 (prevX and curX) are too close to each other (less than the precision) then terminate the algorithm\n",
        "          print(\"The local minimum for f1(x) = (x1-1)^2+(x2-3)^2 occurs at (x1,x2)=(\", curX1, \",\", curX2, \") after underflowing\"\n",
        "            \" precision threshold and is\", f1_x1_x2(curX1, curX2))\n",
        "          break\n",
        "\n",
        "\n",
        "# initializing variables\n",
        "cur_X1 = 0\n",
        "cur_X2 = 0\n",
        "\n",
        "print(\"\\n-------------------------------------f2(x)-----------------------------------------------\\n\")\n",
        "\n",
        "# Iterations for f2(x)\n",
        "for aIter in range(maxIters):\n",
        "\n",
        "      prev_X1 = cur_X1\n",
        "      cur_X1 = cur_X1 - rate * df2_x1(cur_X1, cur_X2)\n",
        "      diff1 = abs(cur_X1-prev_X1)\n",
        "      prev_X2 = cur_X2\n",
        "      cur_X2 = cur_X2 - rate * df2_x2(cur_X1, cur_X2)\n",
        "      diff2 = abs(cur_X2 - prev_X2)\n",
        "      print(\"Iteration \", aIter+1, \"\\n(x1,x2)=(\", cur_X1, \",\", cur_X2, \") => f2(\", cur_X1, \",\", cur_X2, \")=\", f2_x1_x2(cur_X1, cur_X2))  # Print iterations\n",
        "\n",
        "      f2_values_list.append(float(f2_x1_x2(cur_X1, cur_X2)))        # contains values of function f1 at each (x1,x2) point\n",
        "      iter_list2.append(int(aIter + 1))                             # contains iterations number for printing later\n",
        "\n",
        "      if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "        # if prevX and curX are too close to each other (less than the precision) then terminate the algorithm\n",
        "        print(\"The local minimum for f2(x) = (1-(x2-3))^2+20*((x1+3)-(x2-3)^2)^2 occurs at (x1,x2)=(\", cur_X1, \",\", cur_X2, \") after underflowing\"\n",
        "            \" precision threshold and is\", f2_x1_x2(cur_X1, cur_X2))\n",
        "        break\n",
        "\n",
        "# Plotting for f1\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "plt.scatter(iter_list1, f1_values_list, marker='.', color='red', s=0.5)\n",
        "plt.plot([min(iter_list1), max(iter_list1)], [min(f1_values_list), max(f1_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"f1(x1,x2)\")\n",
        "plt.show()\n",
        "\n",
        "# Plotting for f2\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "plt.scatter(iter_list2, f2_values_list, marker='.', color='red', s=0.5)\n",
        "plt.plot([min(iter_list2), max(iter_list2)], [min(f2_values_list), max(f2_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"f2(x1,x2)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UAyAvxoaE7V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**800 iterations**"
      ],
      "metadata": {
        "id": "TLAqb1ysFKt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from decimal import *\n",
        "\n",
        "# definitions of the functions and their partial derivatives\n",
        "def f1_x1_x2(x1, x2):\n",
        "    return (x1-2) ** 2 + (x2-3) ** 2\n",
        "\n",
        "def f2_x1_x2(x1, x2):\n",
        "    return (1 - (x2-3)) ** 2 + 20 * ((x1+3) - (x2-3) ** 2) ** 2\n",
        "\n",
        "def df1_x1(x1, x2):\n",
        "    return (2 * (x1-2))\n",
        "\n",
        "def df1_x2(x1, x2):\n",
        "    return (2 * (x1-3))\n",
        "\n",
        "def df2_x1(x1, x2):\n",
        "    return (40 * (x1-3) - 40 * (x2-3) ** 2)\n",
        "\n",
        "def df2_x2(x1, x2):\n",
        "    return (2 * (x2-4) - 80 * (x1+3) * (x2-3) + 80 * (x2-3) ** 3)\n",
        "\n",
        "# initializing variables\n",
        "\n",
        "rate = 0.0005                      # Learning rate\n",
        "precision = 0.000001\n",
        "curX1 = 0\n",
        "curX2 = 0\n",
        "maxIters = 800                   # maximum number of iterations (modifiable)\n",
        "iters = 0                       # iteration counter\n",
        "iter_list1 = []                 # list stores the iteration number, to use later in the plot\n",
        "iter_list2 = []                 # list stores the iteration number, to use later in the plot\n",
        "f1_values_list = []\n",
        "f2_values_list = []\n",
        "\n",
        "print(\"\\n-------------------------------------f1(x)-----------------------------------------------\\n\")\n",
        "\n",
        "# Iterations for f1(x)\n",
        "for aIter in range(maxIters):\n",
        "\n",
        "      prevX1 = curX1\n",
        "      curX1 = curX1 - rate * df1_x1(curX1, curX2)\n",
        "      diff1 = abs(curX1-prevX1)\n",
        "      prevX2 = curX2\n",
        "      curX2 = curX2 - rate * df1_x2(curX1, curX2)\n",
        "      diff2 = abs(curX2 - prevX2)\n",
        "      print(\"Iteration \", aIter + 1, \"\\n(x1,x2)=(\",curX1, \",\", curX2, \") => f1(\", curX1, \",\", curX2, \")=\", f1_x1_x2(curX1, curX2))  # Print iterations\n",
        "\n",
        "      f1_values_list.append(float(f1_x1_x2(curX1, curX2)))  # contains values of function f1 at each (x1,x2) point\n",
        "      iter_list1.append(int(aIter+1))                       # contains iterations number for printing later\n",
        "\n",
        "      if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "          # if one/both of the 2 variables x1 or x2 (prevX and curX) are too close to each other (less than the precision) then terminate the algorithm\n",
        "          print(\"The local minimum for f1(x) = (x1-1)^2+(x2-3)^2 occurs at (x1,x2)=(\", curX1, \",\", curX2, \") after underflowing\"\n",
        "            \" precision threshold and is\", f1_x1_x2(curX1, curX2))\n",
        "          break\n",
        "\n",
        "\n",
        "# initializing variables\n",
        "cur_X1 = 0\n",
        "cur_X2 = 0\n",
        "\n",
        "print(\"\\n-------------------------------------f2(x)-----------------------------------------------\\n\")\n",
        "\n",
        "# Iterations for f2(x)\n",
        "for aIter in range(maxIters):\n",
        "\n",
        "      prev_X1 = cur_X1\n",
        "      cur_X1 = cur_X1 - rate * df2_x1(cur_X1, cur_X2)\n",
        "      diff1 = abs(cur_X1-prev_X1)\n",
        "      prev_X2 = cur_X2\n",
        "      cur_X2 = cur_X2 - rate * df2_x2(cur_X1, cur_X2)\n",
        "      diff2 = abs(cur_X2 - prev_X2)\n",
        "      print(\"Iteration \", aIter+1, \"\\n(x1,x2)=(\", cur_X1, \",\", cur_X2, \") => f2(\", cur_X1, \",\", cur_X2, \")=\", f2_x1_x2(cur_X1, cur_X2))  # Print iterations\n",
        "\n",
        "      f2_values_list.append(float(f2_x1_x2(cur_X1, cur_X2)))        # contains values of function f1 at each (x1,x2) point\n",
        "      iter_list2.append(int(aIter + 1))                             # contains iterations number for printing later\n",
        "\n",
        "      if diff1 <= precision or diff2 <= precision:\n",
        "\n",
        "        # if prevX and curX are too close to each other (less than the precision) then terminate the algorithm\n",
        "        print(\"The local minimum for f2(x) = (1-(x2-3))^2+20*((x1+3)-(x2-3)^2)^2 occurs at (x1,x2)=(\", cur_X1, \",\", cur_X2, \") after underflowing\"\n",
        "            \" precision threshold and is\", f2_x1_x2(cur_X1, cur_X2))\n",
        "        break\n",
        "\n",
        "# Plotting for f1\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "plt.scatter(iter_list1, f1_values_list, marker='.', color='red', s=0.5)\n",
        "plt.plot([min(iter_list1), max(iter_list1)], [min(f1_values_list), max(f1_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"f1(x1,x2)\")\n",
        "plt.show()\n",
        "\n",
        "# Plotting for f2\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.title(\"rate=\" + str(rate) + \"  precision=\" + str(precision))\n",
        "plt.scatter(iter_list2, f2_values_list, marker='.', color='red', s=0.5)\n",
        "plt.plot([min(iter_list2), max(iter_list2)], [min(f2_values_list), max(f2_values_list)], color='blue',markerfacecolor='red', markersize=10,linestyle='dashed')\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"f2(x1,x2)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I18FzL2IFZtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that in some cases, the algorithm approximates the optimal point at the beginning, in others it approaches it at an intermediate iteration rather than the last one, while in some cases, it gets \"trapped\" and fails to converge.\n",
        "\n"
      ],
      "metadata": {
        "id": "OqK_PNxkFbKj"
      }
    }
  ]
}